{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f300fa98-a638-446e-9f22-b58e43853054",
   "metadata": {},
   "source": [
    "### The first step in optimizing the model is to repeat the data preprocessing done in the original code but with any needed modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ec9e84-e8ff-4250-8ca4-a5d45d62db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e42ce3-7ec0-4eca-ba41-1e31ea273b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in CSV data to a Pandas dataframe\n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e46f773-f9b1-497d-8678-c1e6d778f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS\n",
      "1    34294\n",
      "0        5\n",
      "Name: STATUS, dtype: int64\n",
      "...\n",
      "SPECIAL_CONSIDERATIONS\n",
      "N    34272\n",
      "Y       27\n",
      "Name: SPECIAL_CONSIDERATIONS, dtype: int64\n",
      "...\n",
      "INCOME_AMT\n",
      "0                24388\n",
      "25000-99999       3747\n",
      "100000-499999     3374\n",
      "1M-5M              955\n",
      "1-9999             728\n",
      "10000-24999        543\n",
      "10M-50M            240\n",
      "5M-10M             185\n",
      "50M+               139\n",
      "Name: INCOME_AMT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for column usefulness of columns based on value counts\n",
    "print(\"STATUS\")\n",
    "print(application_df[\"STATUS\"].value_counts())\n",
    "print(\"...\")\n",
    "print(\"SPECIAL_CONSIDERATIONS\")\n",
    "print(application_df[\"SPECIAL_CONSIDERATIONS\"].value_counts())\n",
    "print(\"...\")\n",
    "print(\"INCOME_AMT\")\n",
    "print(application_df[\"INCOME_AMT\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0605cac-572a-4040-8e45-3bc0718dd1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION     INCOME_AMT  ASK_AMT  IS_SUCCESSFUL  \n",
       "0   Association              0     5000              1  \n",
       "1  Co-operative         1-9999   108590              1  \n",
       "2   Association              0     5000              0  \n",
       "3         Trust    10000-24999     6692              1  \n",
       "4         Trust  100000-499999   142590              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME' as well as \"STATUS\" and \"SPECIAL_CONSIDERATIONS\" columns which don't vary enough to justfity inclusion.\n",
    "dropped = application_df.drop(['EIN', 'NAME', \"STATUS\", \"SPECIAL_CONSIDERATIONS\"], axis=1)\n",
    "dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981993d6-f62b-4446-b989-63eb724d56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy dataframe to work with\n",
    "dropped_copy = dropped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ffdd3c-e85d-45c7-86c8-08b0311f1573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "Other      120\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Application types with under 100 instances will be replaced with 'Other'\n",
    "application_types_to_replace = ['T13', 'T12', 'T2', 'T25', 'T14', 'T15', 'T29', 'T17']\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    dropped_copy['APPLICATION_TYPE'] = dropped_copy['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "dropped_copy['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37daa3c8-0219-483d-a4dd-b95bbee45e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue binning with the classification column starting with finding the values to be binned as other\n",
    "v_counts = pd.DataFrame(dropped_copy['CLASSIFICATION'].value_counts())\n",
    "\n",
    "v_counts.reset_index(inplace=True)\n",
    "\n",
    "classifications_to_replace = []\n",
    "\n",
    "for index, row in v_counts.iterrows():\n",
    "    if row[\"CLASSIFICATION\"] < 100:\n",
    "        classifications_to_replace.append(row[\"index\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10338d9d-dd39-46b7-bdcf-05ee38dba864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin the classification column\n",
    "for cls in classifications_to_replace:\n",
    "    dropped_copy['CLASSIFICATION'] = dropped_copy['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "dropped_copy['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41636bb3-e931-45ff-a7b9-4dbd2e532abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0          5000              1                       0                     1   \n",
       "1        108590              1                       0                     0   \n",
       "2          5000              0                       0                     0   \n",
       "3          6692              1                       0                     0   \n",
       "4        142590              1                       0                     0   \n",
       "...         ...            ...                     ...                   ...   \n",
       "34294      5000              0                       0                     0   \n",
       "34295      5000              0                       0                     0   \n",
       "34296      5000              0                       0                     0   \n",
       "34297      5000              1                       0                     0   \n",
       "34298  36500179              0                       0                     0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    1                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "4                         0                    1                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "34298                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "1                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "4                        0                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "34298                    0                    0                    0  ...   \n",
       "\n",
       "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0                       0             1                  0   \n",
       "1                       0             0                  1   \n",
       "2                       0             1                  0   \n",
       "3                       1             0                  0   \n",
       "4                       1             0                  0   \n",
       "...                   ...           ...                ...   \n",
       "34294                   0             1                  0   \n",
       "34295                   0             1                  0   \n",
       "34296                   0             1                  0   \n",
       "34297                   0             1                  0   \n",
       "34298                   0             0                  0   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                           0                         0                   0   \n",
       "1                           0                         0                   0   \n",
       "2                           0                         0                   0   \n",
       "3                           1                         0                   0   \n",
       "4                           0                         1                   0   \n",
       "...                       ...                       ...                 ...   \n",
       "34294                       0                         0                   0   \n",
       "34295                       0                         0                   0   \n",
       "34296                       0                         0                   0   \n",
       "34297                       0                         0                   0   \n",
       "34298                       0                         0                   0   \n",
       "\n",
       "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                     0                       0                0   \n",
       "1                     0                       0                0   \n",
       "2                     0                       0                0   \n",
       "3                     0                       0                0   \n",
       "4                     0                       0                0   \n",
       "...                 ...                     ...              ...   \n",
       "34294                 0                       0                0   \n",
       "34295                 0                       0                0   \n",
       "34296                 0                       0                0   \n",
       "34297                 0                       0                0   \n",
       "34298                 1                       0                0   \n",
       "\n",
       "       INCOME_AMT_5M-10M  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "34294                  0  \n",
       "34295                  0  \n",
       "34296                  0  \n",
       "34297                  0  \n",
       "34298                  0  \n",
       "\n",
       "[34299 rows x 48 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dum = pd.get_dummies(dropped_copy)\n",
    "dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41320e73-770d-450f-80cf-49130d13ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = dum.drop('IS_SUCCESSFUL', axis=1)\n",
    "\n",
    "y = dum['IS_SUCCESSFUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b218a5a-9fef-4d62-bd52-473daf21562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56af7499-405b-4ff8-b51a-7cb2d70f703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11614</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17386</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>333518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25724 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASK_AMT  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "10491     5000                       0                     0   \n",
       "9384      5000                       0                     0   \n",
       "11614     5000                       0                     0   \n",
       "17386     5000                       0                     0   \n",
       "3844      5000                       0                     0   \n",
       "...        ...                     ...                   ...   \n",
       "16850   333518                       0                     0   \n",
       "6265      5000                       0                     0   \n",
       "11284     5000                       0                     0   \n",
       "860       5000                       0                     0   \n",
       "15795     5000                       0                     0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "10491                     0                    1                    0   \n",
       "9384                      0                    1                    0   \n",
       "11614                     0                    1                    0   \n",
       "17386                     0                    1                    0   \n",
       "3844                      0                    0                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "16850                     0                    1                    0   \n",
       "6265                      0                    1                    0   \n",
       "11284                     0                    1                    0   \n",
       "860                       0                    1                    0   \n",
       "15795                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  \\\n",
       "10491                    0                    0                    0   \n",
       "9384                     0                    0                    0   \n",
       "11614                    0                    0                    0   \n",
       "17386                    0                    0                    0   \n",
       "3844                     0                    0                    1   \n",
       "...                    ...                  ...                  ...   \n",
       "16850                    0                    0                    0   \n",
       "6265                     0                    0                    0   \n",
       "11284                    0                    0                    0   \n",
       "860                      0                    0                    0   \n",
       "15795                    0                    0                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T8  ...  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "10491                    0  ...                   1             1   \n",
       "9384                     0  ...                   1             1   \n",
       "11614                    0  ...                   1             1   \n",
       "17386                    0  ...                   1             1   \n",
       "3844                     0  ...                   0             1   \n",
       "...                    ...  ...                 ...           ...   \n",
       "16850                    0  ...                   1             0   \n",
       "6265                     0  ...                   1             1   \n",
       "11284                    0  ...                   1             1   \n",
       "860                      0  ...                   0             1   \n",
       "15795                    0  ...                   1             1   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "10491                  0                       0                         0   \n",
       "9384                   0                       0                         0   \n",
       "11614                  0                       0                         0   \n",
       "17386                  0                       0                         0   \n",
       "3844                   0                       0                         0   \n",
       "...                  ...                     ...                       ...   \n",
       "16850                  0                       0                         0   \n",
       "6265                   0                       0                         0   \n",
       "11284                  0                       0                         0   \n",
       "860                    0                       0                         0   \n",
       "15795                  0                       0                         0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "10491                   0                 0                       0   \n",
       "9384                    0                 0                       0   \n",
       "11614                   0                 0                       0   \n",
       "17386                   0                 0                       0   \n",
       "3844                    0                 0                       0   \n",
       "...                   ...               ...                     ...   \n",
       "16850                   0                 0                       1   \n",
       "6265                    0                 0                       0   \n",
       "11284                   0                 0                       0   \n",
       "860                     0                 0                       0   \n",
       "15795                   0                 0                       0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
       "10491                0                  0  \n",
       "9384                 0                  0  \n",
       "11614                0                  0  \n",
       "17386                0                  0  \n",
       "3844                 0                  0  \n",
       "...                ...                ...  \n",
       "16850                0                  0  \n",
       "6265                 0                  0  \n",
       "11284                0                  0  \n",
       "860                  0                  0  \n",
       "15795                0                  0  \n",
       "\n",
       "[25724 rows x 47 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview the training data\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a3d822-129a-46df-a211-9db343657709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b999949-eb1d-4556-a6e1-f6a2ef0e328a",
   "metadata": {},
   "source": [
    "# Model optimization attempt One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a16173e-058b-4a37-8941-8ac1b5acbd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 8)                 384       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn_one = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# First hidden layer\n",
    "number_input_features = 47\n",
    "\n",
    "nn_one.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_one.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_one.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_one.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b7b80-b8fe-4a1d-8ad4-9eb65e2f6d8d",
   "metadata": {},
   "source": [
    "### For this first attempt at optimization, the number of units in the first hidden layer has been increased to 8 and the number in the second hidden layer has been increased to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9899d2-aac4-4d7a-80cb-14127f73f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_one.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697eac98-f163-4896-863f-1662a469bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.6284 - accuracy: 0.6603\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5665 - accuracy: 0.7186\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5567 - accuracy: 0.7245\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5523 - accuracy: 0.7269\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5506 - accuracy: 0.7292\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5495 - accuracy: 0.7302\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5485 - accuracy: 0.7315\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5480 - accuracy: 0.7306\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 828us/step - loss: 0.5476 - accuracy: 0.7317\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 822us/step - loss: 0.5469 - accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5469 - accuracy: 0.7318\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5464 - accuracy: 0.7322\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5459 - accuracy: 0.7328\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 822us/step - loss: 0.5461 - accuracy: 0.7331\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5454 - accuracy: 0.7336\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5453 - accuracy: 0.7334\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 823us/step - loss: 0.5453 - accuracy: 0.7331\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7318\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 891us/step - loss: 0.5449 - accuracy: 0.7335\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 905us/step - loss: 0.5447 - accuracy: 0.7327\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5445 - accuracy: 0.7336\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 826us/step - loss: 0.5445 - accuracy: 0.7327\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 871us/step - loss: 0.5441 - accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5437 - accuracy: 0.7330\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5438 - accuracy: 0.7341\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 815us/step - loss: 0.5436 - accuracy: 0.7315\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 835us/step - loss: 0.5436 - accuracy: 0.7325\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5435 - accuracy: 0.7325\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 815us/step - loss: 0.5434 - accuracy: 0.7337\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 858us/step - loss: 0.5431 - accuracy: 0.7334\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5434 - accuracy: 0.7336\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 827us/step - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 823us/step - loss: 0.5429 - accuracy: 0.7336\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 826us/step - loss: 0.5431 - accuracy: 0.7345\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 824us/step - loss: 0.5429 - accuracy: 0.7329\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 831us/step - loss: 0.5429 - accuracy: 0.7336\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5431 - accuracy: 0.7325\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5428 - accuracy: 0.7338\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7339\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5422 - accuracy: 0.7341\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5424 - accuracy: 0.7337\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 838us/step - loss: 0.5424 - accuracy: 0.7336\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5427 - accuracy: 0.7336\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5423 - accuracy: 0.7338\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 848us/step - loss: 0.5422 - accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 846us/step - loss: 0.5422 - accuracy: 0.7345\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5419 - accuracy: 0.7335\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5423 - accuracy: 0.7332\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5422 - accuracy: 0.7342\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 846us/step - loss: 0.5419 - accuracy: 0.7355\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5424 - accuracy: 0.7338\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5419 - accuracy: 0.7343\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5419 - accuracy: 0.7350\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5420 - accuracy: 0.7326\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5418 - accuracy: 0.7346\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5416 - accuracy: 0.7341\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 833us/step - loss: 0.5419 - accuracy: 0.7345\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.5418 - accuracy: 0.7341\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5420 - accuracy: 0.7334\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5413 - accuracy: 0.7335\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5414 - accuracy: 0.7338\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5413 - accuracy: 0.7351\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5416 - accuracy: 0.7345\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5415 - accuracy: 0.7348\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 834us/step - loss: 0.5416 - accuracy: 0.7345\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5415 - accuracy: 0.7349\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 853us/step - loss: 0.5413 - accuracy: 0.7332\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5417 - accuracy: 0.7338\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5410 - accuracy: 0.7350\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 847us/step - loss: 0.5413 - accuracy: 0.7339\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5412 - accuracy: 0.7355\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 828us/step - loss: 0.5410 - accuracy: 0.7343\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5406 - accuracy: 0.7352\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5413 - accuracy: 0.7342\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5412 - accuracy: 0.7346\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 847us/step - loss: 0.5410 - accuracy: 0.7345\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5408 - accuracy: 0.7343\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 844us/step - loss: 0.5409 - accuracy: 0.7339\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5410 - accuracy: 0.7347\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 847us/step - loss: 0.5408 - accuracy: 0.7350\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 844us/step - loss: 0.5407 - accuracy: 0.7345\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5408 - accuracy: 0.7353\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5406 - accuracy: 0.7346\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5409 - accuracy: 0.7335\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.5409 - accuracy: 0.7338\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 828us/step - loss: 0.5408 - accuracy: 0.7352\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 847us/step - loss: 0.5409 - accuracy: 0.7352\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.5409 - accuracy: 0.7357\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 828us/step - loss: 0.5406 - accuracy: 0.7344\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 835us/step - loss: 0.5409 - accuracy: 0.7359\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5407 - accuracy: 0.7353\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5406 - accuracy: 0.7358\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 830us/step - loss: 0.5403 - accuracy: 0.7346\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5405 - accuracy: 0.7354\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 834us/step - loss: 0.5406 - accuracy: 0.7339\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 839us/step - loss: 0.5405 - accuracy: 0.7351\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5406 - accuracy: 0.7360\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 830us/step - loss: 0.5406 - accuracy: 0.7353\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5403 - accuracy: 0.7362\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5404 - accuracy: 0.7347\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_one = nn_one.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0cc1db7-d4ba-466d-9fc1-c407f6debf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5525 - accuracy: 0.7290 - 254ms/epoch - 947us/step\n",
      "Loss: 0.552502453327179, Accuracy: 0.7289795875549316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_one_loss, model_one_accuracy = nn_one.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_one_loss}, Accuracy: {model_one_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e0c5a-5451-4257-b6f0-e8cfffd63d6a",
   "metadata": {},
   "source": [
    "### The fact that this first model doesn't significantly improve beyond about the first ten ephochs is concerning. Adding more epochs to training this model is clearly not going to help. For the second attempt at optimization, more hidden layers will be added instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe555687-d14d-4b10-b30e-547650277f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 5)                 240       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 48        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339\n",
      "Trainable params: 339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn_two = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# First hidden layer\n",
    "number_input_features = 47\n",
    "\n",
    "nn_two.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_two.add(tf.keras.layers.Dense(units=8, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_two.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_two.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_two.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ac45e21-ab83-4b4c-9c7b-3c41f573e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_two.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "297c1736-1b4f-4f28-8845-371cc4e3334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.6257 - accuracy: 0.6860\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 870us/step - loss: 0.5866 - accuracy: 0.7213\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5760 - accuracy: 0.7258\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5723 - accuracy: 0.7296\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 853us/step - loss: 0.5708 - accuracy: 0.7291\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 860us/step - loss: 0.5694 - accuracy: 0.7304\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5685 - accuracy: 0.7299\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5678 - accuracy: 0.7308\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 884us/step - loss: 0.5676 - accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5672 - accuracy: 0.7310\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5668 - accuracy: 0.7305\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5660 - accuracy: 0.7317\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 881us/step - loss: 0.5652 - accuracy: 0.7315\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 878us/step - loss: 0.5631 - accuracy: 0.7311\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 865us/step - loss: 0.5620 - accuracy: 0.7311\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 867us/step - loss: 0.5608 - accuracy: 0.7307\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5596 - accuracy: 0.7296\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 862us/step - loss: 0.5585 - accuracy: 0.7308\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5562 - accuracy: 0.7311\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 881us/step - loss: 0.5552 - accuracy: 0.7313\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5546 - accuracy: 0.7308\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 882us/step - loss: 0.5541 - accuracy: 0.7304\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 856us/step - loss: 0.5534 - accuracy: 0.7321\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5528 - accuracy: 0.7313\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 889us/step - loss: 0.5528 - accuracy: 0.7318\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5523 - accuracy: 0.7310\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 864us/step - loss: 0.5525 - accuracy: 0.7312\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 884us/step - loss: 0.5522 - accuracy: 0.7304\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5518 - accuracy: 0.7311\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 870us/step - loss: 0.5518 - accuracy: 0.7318\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5513 - accuracy: 0.7302\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5518 - accuracy: 0.7315\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 919us/step - loss: 0.5513 - accuracy: 0.7322\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 876us/step - loss: 0.5514 - accuracy: 0.7320\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 882us/step - loss: 0.5513 - accuracy: 0.7313\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 878us/step - loss: 0.5513 - accuracy: 0.7323\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 876us/step - loss: 0.5512 - accuracy: 0.7318\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 910us/step - loss: 0.5512 - accuracy: 0.7309\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 901us/step - loss: 0.5510 - accuracy: 0.7318\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 898us/step - loss: 0.5510 - accuracy: 0.7318\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 884us/step - loss: 0.5506 - accuracy: 0.7312\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5507 - accuracy: 0.7314\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 899us/step - loss: 0.5508 - accuracy: 0.7319\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 916us/step - loss: 0.5506 - accuracy: 0.7316\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 883us/step - loss: 0.5506 - accuracy: 0.7319\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 886us/step - loss: 0.5507 - accuracy: 0.7324\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5505 - accuracy: 0.7312\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 888us/step - loss: 0.5505 - accuracy: 0.7316\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5504 - accuracy: 0.7320\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 886us/step - loss: 0.5503 - accuracy: 0.7317\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 887us/step - loss: 0.5505 - accuracy: 0.7313\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 883us/step - loss: 0.5504 - accuracy: 0.7327\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5500 - accuracy: 0.7316\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 882us/step - loss: 0.5502 - accuracy: 0.7307\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5501 - accuracy: 0.7316\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 888us/step - loss: 0.5502 - accuracy: 0.7322\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5501 - accuracy: 0.7323\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 891us/step - loss: 0.5497 - accuracy: 0.7319\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 904us/step - loss: 0.5497 - accuracy: 0.7322\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5499 - accuracy: 0.7316\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 906us/step - loss: 0.5495 - accuracy: 0.7319\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 889us/step - loss: 0.5499 - accuracy: 0.7318\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 884us/step - loss: 0.5498 - accuracy: 0.7317\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5497 - accuracy: 0.7320\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 896us/step - loss: 0.5496 - accuracy: 0.7319\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 898us/step - loss: 0.5493 - accuracy: 0.7321\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 895us/step - loss: 0.5496 - accuracy: 0.7316\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 898us/step - loss: 0.5496 - accuracy: 0.7320\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5496 - accuracy: 0.7324\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 894us/step - loss: 0.5493 - accuracy: 0.7316\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 911us/step - loss: 0.5493 - accuracy: 0.7326\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 907us/step - loss: 0.5497 - accuracy: 0.7319\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 908us/step - loss: 0.5495 - accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5491 - accuracy: 0.7330\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 903us/step - loss: 0.5492 - accuracy: 0.7331\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5493 - accuracy: 0.7320\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5493 - accuracy: 0.7318\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 898us/step - loss: 0.5493 - accuracy: 0.7325\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 880us/step - loss: 0.5490 - accuracy: 0.7320\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 910us/step - loss: 0.5494 - accuracy: 0.7317\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 874us/step - loss: 0.5494 - accuracy: 0.7329\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 916us/step - loss: 0.5494 - accuracy: 0.7320\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5493 - accuracy: 0.7316\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 883us/step - loss: 0.5493 - accuracy: 0.7317\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 875us/step - loss: 0.5491 - accuracy: 0.7325\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5490 - accuracy: 0.7325\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5490 - accuracy: 0.7327\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 871us/step - loss: 0.5489 - accuracy: 0.7325\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 904us/step - loss: 0.5488 - accuracy: 0.7325\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 911us/step - loss: 0.5489 - accuracy: 0.7321\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5484 - accuracy: 0.7318\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5487 - accuracy: 0.7325\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5488 - accuracy: 0.7319\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 876us/step - loss: 0.5490 - accuracy: 0.7328\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 879us/step - loss: 0.5484 - accuracy: 0.7318\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 876us/step - loss: 0.5489 - accuracy: 0.7322\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5489 - accuracy: 0.7322\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 938us/step - loss: 0.5487 - accuracy: 0.7325\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5487 - accuracy: 0.7331\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5488 - accuracy: 0.7316\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_two = nn_two.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c4cfea0-dea8-416f-8765-97513ada8cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5554 - accuracy: 0.7287 - 232ms/epoch - 866us/step\n",
      "Loss: 0.5554271340370178, Accuracy: 0.7287463545799255\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_two_loss, model_two_accuracy = nn_two.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_two_loss}, Accuracy: {model_two_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40503b4-4b75-4252-a4ec-9f37e8e6bd71",
   "metadata": {},
   "source": [
    "### This second attempt actually fared just slightly worse, so including another hidden layer was not an effective strategy for optimizing the model. For this third attempt, maybe changing the activation functions will help. The last layer will stay signmoid but earlier layers will be switched from relu to another activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dd1ab50-f32a-4432-a17c-0ab2b8e3081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 8)                 384       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn_three = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# First hidden layer\n",
    "number_input_features = 47\n",
    "\n",
    "nn_three.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_three.add(tf.keras.layers.Dense(units=10, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn_three.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_three.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6f347b5-17f4-49e4-81b3-cbf8f3e3b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_three.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b5df160-0253-406d-a080-4f3ce7a6fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 823us/step - loss: 0.5942 - accuracy: 0.6984\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5628 - accuracy: 0.7269\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5579 - accuracy: 0.7296\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 825us/step - loss: 0.5556 - accuracy: 0.7301\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5542 - accuracy: 0.7303\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 834us/step - loss: 0.5530 - accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 834us/step - loss: 0.5518 - accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5512 - accuracy: 0.7299\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5503 - accuracy: 0.7308\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5500 - accuracy: 0.7308\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 843us/step - loss: 0.5494 - accuracy: 0.7301\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 841us/step - loss: 0.5489 - accuracy: 0.7310\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5485 - accuracy: 0.7318\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5480 - accuracy: 0.7313\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 838us/step - loss: 0.5477 - accuracy: 0.7315\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5474 - accuracy: 0.7318\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 844us/step - loss: 0.5475 - accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5470 - accuracy: 0.7313\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5467 - accuracy: 0.7313\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5464 - accuracy: 0.7316\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 847us/step - loss: 0.5462 - accuracy: 0.7318\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5463 - accuracy: 0.7322\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 832us/step - loss: 0.5458 - accuracy: 0.7318\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5457 - accuracy: 0.7314\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5454 - accuracy: 0.7317\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 849us/step - loss: 0.5454 - accuracy: 0.7324\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 851us/step - loss: 0.5451 - accuracy: 0.7320\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 846us/step - loss: 0.5451 - accuracy: 0.7331\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5445 - accuracy: 0.7318\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5445 - accuracy: 0.7331\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 852us/step - loss: 0.5443 - accuracy: 0.7325\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 854us/step - loss: 0.5445 - accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5441 - accuracy: 0.7327\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 852us/step - loss: 0.5438 - accuracy: 0.7332\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5438 - accuracy: 0.7350\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 854us/step - loss: 0.5437 - accuracy: 0.7324\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 852us/step - loss: 0.5438 - accuracy: 0.7320\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 848us/step - loss: 0.5434 - accuracy: 0.7329\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5435 - accuracy: 0.7336\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5434 - accuracy: 0.7334\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5434 - accuracy: 0.7332\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 816us/step - loss: 0.5431 - accuracy: 0.7344\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 839us/step - loss: 0.5428 - accuracy: 0.7344\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 867us/step - loss: 0.5427 - accuracy: 0.7327\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 884us/step - loss: 0.5429 - accuracy: 0.7345\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5427 - accuracy: 0.7334\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5425 - accuracy: 0.7348\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 867us/step - loss: 0.5424 - accuracy: 0.7341\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 862us/step - loss: 0.5422 - accuracy: 0.7339\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5422 - accuracy: 0.7333\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5421 - accuracy: 0.7338\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.5418 - accuracy: 0.7346\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 864us/step - loss: 0.5419 - accuracy: 0.7347\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5420 - accuracy: 0.7341\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 870us/step - loss: 0.5419 - accuracy: 0.7346\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 872us/step - loss: 0.5415 - accuracy: 0.7338\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 878us/step - loss: 0.5417 - accuracy: 0.7336\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 870us/step - loss: 0.5418 - accuracy: 0.7343\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5415 - accuracy: 0.7345\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 872us/step - loss: 0.5415 - accuracy: 0.7339\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 871us/step - loss: 0.5416 - accuracy: 0.7341\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5413 - accuracy: 0.7348\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 875us/step - loss: 0.5417 - accuracy: 0.7345\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 873us/step - loss: 0.5415 - accuracy: 0.7347\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 871us/step - loss: 0.5413 - accuracy: 0.7348\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 863us/step - loss: 0.5415 - accuracy: 0.7340\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5412 - accuracy: 0.7347\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 862us/step - loss: 0.5413 - accuracy: 0.7349\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 846us/step - loss: 0.5412 - accuracy: 0.7354\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 875us/step - loss: 0.5410 - accuracy: 0.7345\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 854us/step - loss: 0.5410 - accuracy: 0.7348\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 864us/step - loss: 0.5409 - accuracy: 0.7354\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 881us/step - loss: 0.5409 - accuracy: 0.7351\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 882us/step - loss: 0.5411 - accuracy: 0.7350\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 860us/step - loss: 0.5409 - accuracy: 0.7345\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 879us/step - loss: 0.5411 - accuracy: 0.7350\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.5408 - accuracy: 0.7339\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5409 - accuracy: 0.7345\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5406 - accuracy: 0.7350\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 867us/step - loss: 0.5407 - accuracy: 0.7350\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 873us/step - loss: 0.5407 - accuracy: 0.7357\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5407 - accuracy: 0.7353\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 863us/step - loss: 0.5404 - accuracy: 0.7350\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5406 - accuracy: 0.7354\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5406 - accuracy: 0.7353\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5405 - accuracy: 0.7356\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5404 - accuracy: 0.7355\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5405 - accuracy: 0.7357\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5405 - accuracy: 0.7353\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 873us/step - loss: 0.5403 - accuracy: 0.7348\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 877us/step - loss: 0.5404 - accuracy: 0.7351\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 874us/step - loss: 0.5402 - accuracy: 0.7362\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5403 - accuracy: 0.7350\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 863us/step - loss: 0.5400 - accuracy: 0.7349\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 864us/step - loss: 0.5402 - accuracy: 0.7353\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 868us/step - loss: 0.5405 - accuracy: 0.7352\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 858us/step - loss: 0.5402 - accuracy: 0.7345\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 867us/step - loss: 0.5402 - accuracy: 0.7346\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5401 - accuracy: 0.7352\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 853us/step - loss: 0.5402 - accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_three = nn_three.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3643ce24-a7f9-41cf-bf8c-5a13ef86c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5525 - accuracy: 0.7315 - 234ms/epoch - 872us/step\n",
      "Loss: 0.552477240562439, Accuracy: 0.7315452098846436\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_three_loss, model_three_accuracy = nn_three.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_three_loss}, Accuracy: {model_three_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a883c-1fbb-4d0f-b7ca-fc78a52772e1",
   "metadata": {},
   "source": [
    "### This third attempt at optimization seems to have fared slightly better than the other two. Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "438ae31d-15c8-4b28-809b-20c8962c73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.552502453327179, Accuracy: 0.7289795875549316\n",
      "Loss: 0.5554271340370178, Accuracy: 0.7287463545799255\n",
      "Loss: 0.552477240562439, Accuracy: 0.7315452098846436\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {model_one_loss}, Accuracy: {model_one_accuracy}\")\n",
    "print(f\"Loss: {model_two_loss}, Accuracy: {model_two_accuracy}\")\n",
    "print(f\"Loss: {model_three_loss}, Accuracy: {model_three_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12e890-4804-4089-ab79-d66d0c1ff2b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
